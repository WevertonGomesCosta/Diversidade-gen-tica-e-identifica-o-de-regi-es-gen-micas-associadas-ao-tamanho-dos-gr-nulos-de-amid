---
title: "Home"
author: 
  - Costa, W. G.^[Weverton Gomes da Costa, Pós-Doutorando, Embrapa Mandioca e Fruticultura, wevertonufv@gmail.com]
date: "`r Sys.Date()`"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

# Diversidade Genética do Tamanho dos Grânulos de Amido na Cultura da Mandioca (Cassava)

Este projeto tem como objetivo realizar uma análise da diversidade genética do tamanho dos grânulos de amido na cultura da mandioca. Serão utilizados dados coletados em diferentes anos, visando identificar a variação existente nos genótipos da mandioca.

## Pacotes

Nesta análise, utilizaremos os seguintes pacotes do R:

```{r}
library(tidyverse)        # Conjunto de pacotes para manipulação e visualização de dados
library(DataExplorer)    # Ferramentas para análise exploratória de dados
library(kableExtra)      # Melhorias para a criação de tabelas
library(metan)           # Meta-análise
library(ggthemes)        # Temas adicionais para gráficos ggplot2
library(factoextra)      # Ferramentas para análise de fatores e agrupamentos
library(ade4)            # Análise de dados exploratória multivariada
library(missForest)      # Imputação de dados ausentes
library(RColorBrewer)    # Esquemas de cores personalizados
library(corrplot)        # Visualização de matrizes de correlação
library(adegenet)        # Análise genética de populações
library(gplots)          # Ferramentas para visualização de dados
#library(LDheatmap)       # Visualização de estrutura de ligação (linkage disequilibrium)
library(compiler)        # Compilação de funções para melhorar a velocidade de execução
library(scatterplot3d)   # Gráficos de dispersão em 3D
library(ComplexHeatmap)  # Visualização de dados complexos em heatmap
library(circlize)        # Visualização circular de dados
library(dendextend)      # Extensões para manipulação de dendrogramas
library(doParallel)
library(foreach)
```


## Análise Descritiva

Nesta etapa, serão realizadas as seguintes tarefas:

### Leitura e pré-processamento dos dados

Os dados são lidos a partir do arquivo "dados_RVA.xlsx" e passam por um processo de pré-processamento. Isso inclui a limpeza dos nomes das colunas, a seleção das variáveis relevantes, a transformação dos tipos de dados, a remoção de valores ausentes e o cálculo da média para as variáveis numéricas. Também são realizadas outras transformações nos dados, como a conversão de fatores e a filtragem de registros com valores inválidos.

```{r}
nomes_corretos <-
  readxl::read_xlsx("data/Label Taxa nome dos clones GBS DART CHIP.xlsx") %>%
  mutate_if(is.logical, as.character) %>%
  pivot_longer(cols = c(2, 7:13),
               names_to = "synonyms",
               values_to = "BAD_NAME") %>%
  select(`GOOD NAME`, BAD_NAME) %>%
  rename(amostras = BAD_NAME) %>% 
  count(`GOOD NAME`, amostras) %>% 
  na.omit() %>% 
  select(1,2)

dados <- readxl::read_xlsx("data/dados_RVA.xlsx") %>%
  janitor::clean_names() %>%
  select(amostras, ano, ensaio, repeticao:pasting_temp) %>%
  mutate_if(is.character, as.factor) %>%
  left_join(nomes_corretos) %>% 
  mutate(repeticao = as.factor(ifelse(repeticao %% 2 == 0, 1, 2)),
         ano = as.factor(ano),
         amostras = ifelse(is.na(`GOOD NAME`), amostras, `GOOD NAME`)) %>%
  group_by(amostras, ano, ensaio, repeticao) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  ungroup() %>% 
  distinct()
```

### Contagem de genótipos

Nesta etapa, é realizada a contagem de genótipos que foram avaliados para cada ano. 

```{r}
# Contagem de genótipos
dados2 <- dados %>%
  count(amostras) %>% 
  count(n) %>% 
  arrange(n)

# Tabela com contagem de genótipos
dados2 %>%
  kbl(
    escape = FALSE,
    align = 'c',
    col.names = c("Nº de Genótipos", "Contagem")
  ) %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```

A maioria dos genótipos foram repetidos em mais de um ano, o que é desejável para a análise.

### Contagem de genótipos por ano

Nesta etapa, é realizada a contagem do número de genótipos para cada ano. O objetivo é identificar a quantidade de genótipos presentes em cada ano de coleta dos dados.

```{r}
# Contagem de genótipos por ano
dados2 <- dados %>%
  count(ano, amostras)

# Tabela com contagem de genótipos por ano
dados2 %>%
  group_by(ano) %>%
  summarise(`Nº de genótipos` = length(amostras)) %>%
  kbl(
    escape = FALSE,
    align = 'c',
    col.names = c("Ano", "Nº de genótipos")
  ) %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```

Observamos que os anos de 2017, 2018 e 2020 são os anos com a menor quantidade de genótipos. No entanto, continuaremos a análise descritiva para verificar se isso será algo problemático.

```{r}
dados2<- dados %>% 
  count(ano, amostras)
  
genmat = model.matrix( ~ -1 + amostras, data = dados2)
envmat = model.matrix( ~ -1 + ano, data = dados2)
genenvmat = t(envmat) %*% genmat
genenvmat_ch = ifelse(genenvmat == 1, "Present", "Abscent")

genenvmat %*% t(genenvmat) %>%
  kbl(escape = F,
      align = 'c') %>%
  kable_classic(
    "hover",
    full_width = F,
    position = "center",
    fixed_thead = T
  )
```

Não houve nenhum clone reptido em todos os anos.

### Distribuição de ensaios e repetição por ano

Em seguida, verificamos a distribuição das características por ano utilizando a função `plot_bar` com o argumento `by = "ano"`. Isso nos permite gerar gráficos de barras que mostram a distribuição dos valores de cada variável em cada ano.

```{r}
plot_bar(dados, by = "ano", ggtheme = theme_gdocs())
```

Ao observar os resultados, identificamos que alguns ensaios possuem anos diferentes na coleta dos dados. Mas como o ano indica o ano de extração do amido e no máximo poderia ter sido obtido no ano posterior, como é o caso de todos os ensaios, vamos manter os dados assim.

### Análise das variáveis

Realizamos uma análise das variáveis presentes nos dados, buscando entender a distribuição e características de cada uma delas.

Primeiramente, observamos um resumo dos dados pelas medidas descritivas.

```{r}
# Resumo dos dados pelas medidas descritivas
summary(dados) %>% 
  kbl(
    escape = FALSE,
    align = 'c'
  ) %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```

Para peak_1 a setback, podemos observar uma discrepância dos valores mínimos até o 1º quartil, ou seja, esses dados possivelmente serão considerados outliers.

Prosseguindo com a análise, avaliaremos a distribuição por ano utilizando a função plot_boxplot, agora agrupando os dados por ano.

```{r}
# Distribuição por ano usando boxplots
plot_boxplot(
  dados,
  by = "ano",
  nrow = 4,
  ggtheme = theme_gdocs(),
  geom_boxplot_args = list(outlier.colour = "red", outlier.shape = 1)
)
```

O ano de 2017 apresenta uma baixa variação para a maioria das características, mas segue dentro do esperado quando comparado com os demais anos. Assim, iremos prosseguir inicialmente com todos os dados.

### Análise das amostras

Nesta etapa, realizamos uma análise das amostras presentes nos ensaios, com o objetivo de verificar detalhes dos dados e identificar possíveis problemas ou discrepâncias.

Primeiramente, verificamos os detalhes dos dados por ensaio para todas as variáveis. Utilizamos a função ge_details para obter informações como média, desvio padrão, mínimo, máximo e contagem de valores ausentes para cada variável e ensaio.

```{r}
# Detalhes dos dados por ensaio
ge_details(dados, ano, amostras, resp = everything()) %>%
  t() %>%
  kbl(escape = FALSE, align = 'c') %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```

Observamos que a variável setback apresenta coeficiente de variação (CV) alto, indicando uma maior variabilidade e possíveis valores discrepantes em alguns anos. Além disso o clone BGM-0895 no ano de 2017 apresentou menores valores para várias cracterísticas vamos eliminá-lo e verificar novamente os detalhes dos dados.


```{r}
dados <- dados %>% 
  filter(amostras != "BGM-0895") %>% 
  droplevels()

# Detalhes dos dados por ensaio
ge_details(dados, ano, amostras, resp = everything()) %>%
  t() %>%
  kbl(escape = FALSE, align = 'c') %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```


Também realizamos uma inspeção visual dos dados, removendo as colunas referentes às amostras e aos anos. Utilizamos a função `inspect` para gerar uma visualização dos dados em forma de tabela, com a opção de exibir gráficos para uma melhor compreensão. Os resultados são apresentados em uma tabela formatada.

```{r}
dados %>%
  select(-amostras, -ensaio) %>%
  inspect(verbose = FALSE, plot = TRUE) %>%
  kbl(escape = FALSE, align = 'c') %>%
  kable_classic(
    "hover",
    full_width = FALSE,
    position = "center",
    fixed_thead = TRUE
  )
```

Em seguida, analisamos os histogramas das variáveis quantitativas. Utilizamos a função `plot_histogram` para gerar histogramas que mostram a distribuição dos valores de cada variável quantitativa.

```{r}
plot_histogram(dados, ggtheme = theme_gdocs())
```

Ao examinar os histogramas, identificamos que as variáveis aparentemente seguem uma distribuição normal. Portanto, podemos prosseguir com a análise de modelos mistos.

## Modelos Mistos

### Função para obter os parâmetros

A função analise_metan_joint é definida para realizar a análise de metan em um modelo misto específico. Ela extrai os parâmetros de interesse, como a herdabilidade (H2), os valores BLUPs e os valores preditos. Os resultados são retornados como um tibble.

```{r}
analise_metan_joint <- function(model, trait) {
  H2 <- get_model_data(model, "genpar") %>%
    filter(Parameters == "Heritability") %>%
    pull(trait)
  
  vcomp <- get_model_data(model, what = "vcomp")
  
  parameters <- get_model_data(model)
  
  BLUPS <- get_model_data(model, "ranef")$GEN
  
  Predicted_values <- predict(model) %>%
    group_by(GEN) %>%
    summarise(across(where(is.numeric), mean)) %>%
    pull(trait)
  
  return(
    tibble(
      trait = trait,
      H2 = H2,
      germplasmName = BLUPS[[1]],
      BLUPS = BLUPS[[2]],
      parameters = list(parameters),
      vcomp = list(vcomp),
      Predicted = Predicted_values
    )
  )
}

```

### Obtenção dos BLUPs

Nesta etapa, realizamos a obtenção dos valores BLUPs (melhores predições lineares não viesadas) para cada característica (trait) utilizando modelos mistos. O processo é realizado em paralelo, utilizando múltiplos núcleos de processamento para otimizar a velocidade de execução.

```{r}
traits <- colnames(dados)[5:ncol(dados)]

# Registrar os núcleos a serem usados
registerDoParallel(cores = detectCores())

# Loop externo
BLUPS_join <-
  foreach(
    trait = traits,
    .combine = bind_rows,
    .multicombine = TRUE,
    .verbose = TRUE
  ) %dopar% {
    
    library(dplyr)
    library(metan)
    
    DRG <- list()
    
    data <- dados %>%
      select(1:4, all_of(trait)) %>%
      na.omit() %>%
      droplevels()
    
    model <-
      gamem_met(
        data,
        env = ano,
        gen = amostras,
        rep = repeticao,
        resp = sym(trait)
      )
    
    drg <- list(analise_metan_joint(model, trait))
    DRG <- append(DRG, drg)
  }

# Finalizar o registro dos núcleos
registerDoSEQ()
```

O gráfico de densidade é gerado utilizando a variável BLUPS_join como base de dados. Ele exibe as densidades para cada característica (trait) usando diferentes preenchimentos e cores.

```{r}
BLUPS_join %>%
  ggplot(aes(Predicted, after_stat(count), fill = trait, color = trait)) +
  geom_density(show.legend = FALSE)  +
  facet_wrap(vars(trait), scales = "free", strip.position = "bottom") +
  theme_classic() +
  theme(strip.background = element_blank(),
        strip.placement = "outside") +
  labs(y = "Density", x = "") +
  scale_fill_gdocs() +
  scale_color_gdocs() +
  geom_vline(aes(xintercept = mean(Predicted), colour = "black"), linetype = "dashed", show.legend = F) +
   geom_vline(aes(xintercept = quantile(Predicted, probs = 0.25), colour = "indianred4"), linetype = 2, show.legend = F) +
   geom_vline(aes(xintercept = quantile(Predicted, probs = 0.75), colour = "indianred4"), linetype = 2, show.legend = F)
```

Os parâmetros são obtidos a partir da junção dos data frames contidos em BLUPS_join$parameters usando a função merge. Os números nas colunas (exceto a primeira coluna) são arredondados para 4 casas decimais. O resultado é exibido como uma tabela formatada usando o pacote kableExtra.

```{r}
parametros <- Reduce(function(x, y) merge(x, y, all = TRUE), BLUPS_join$parameters)
parametros[,-1] <- as.data.frame(lapply(parametros[,-1], function(x) round(x, 4)))

parametros %>%
  kbl(escape = FALSE, align = 'c') %>%
  kable_classic("hover", full_width = FALSE, position = "center", fixed_thead = TRUE)
```

Os componetnes de variância são obtidos a partir da junção dos data frames contidos em BLUPS_join$vcomp usando a função merge. Os números nas colunas (exceto a primeira coluna) são arredondados para 4 casas decimais. O resultado é exibido como uma tabela formatada usando o pacote kableExtra.

```{r}
vcomp <- Reduce(function(x, y) merge(x, y, all = TRUE), BLUPS_join$vcomp)
vcomp[,-1] <- as.data.frame(lapply(vcomp[,-1], function(x) round(x, 4)))

vcomp %>%
  kbl(escape = FALSE, align = 'c') %>%
  kable_classic("hover", full_width = FALSE, position = "center", fixed_thead = TRUE)
```

```{r}
library(ggthemes)

library(GGally)

varcomp <- varcomp |>
  select(grp, contains("vcov")) |>
  pivot_longer(cols = 2:18,
               names_to = "Traits",
               values_to = "vcov") |> 
  mutate(Traits = factor(str_split_i(Traits, "vcov.",-1),labels = c(
    "Mite",
    "StC",
    "Plant.Height",
    "Branching",
    "Root.Le",
    "Stem.D",
    "Root.Di",
    "HI",
    "DMC",
    "Nstem.Plant",
    "N_Roots",
    "PltArc",
    "ShY",
    "StY",
    "FRY",
    "Leaf.Ret",
    "Stand6MAP"
  )),
  grp = str_replace_all(grp,":","."))

varcomp |> 
  ggplot(aes(x = Traits, y = vcov, fill = grp, by = Traits)) +
  geom_col(position = "fill")+ 
  labs(y="Value",
       x="Traits",
       fill = "VarComp")+
  scale_fill_gdocs()+
  theme_minimal()+
  theme(text = element_text(size = 25, face = "bold"),
    axis.text.x = element_text(
      size = 20,
      angle = 45,
      hjust = 1,
      vjust = 1
    )) 

ggsave("output/varcomp.tiff", width = 16, height = 8)

```

### Salvando os BLUPs e os parametros

```{r}
save(BLUPS_join, file = "output/BLUPS.Rdata")

save(parametros, file = "output/parametros.Rdata")

save(vcomp, file = "output/vcomp.Rdata")
```

## Imputação de dados

```{r}
# Imputação de dados

# Selecionar as colunas necessárias e transformar em matriz
BLUPS <- BLUPS_join %>%
  dplyr::select(trait, germplasmName, BLUPS) %>%
  pivot_wider(names_from = trait, values_from = BLUPS) %>%
  column_to_rownames(var = "germplasmName")

# Realizar a imputação de valores ausentes usando o método missForest
TCC.imp <- missForest(BLUPS, maxiter = 10, ntree = 200, mtry = floor(sqrt(ncol(BLUPS))))

# Salvar os valores imputados em um arquivo
write.table(TCC.imp$ximp, "BLUPs_imputados.txt")

```

### Histograma

```{r}
phen <-
  read.table(
    "BLUPs imputados.txt",
    header = TRUE,
    sep = "",
    na.strings = "NA",
    dec = ".",
    strip.white = TRUE
  )
```

### Correlações de Pearson

```{r}
phen <- TCC.imp$ximp
# Calcular a matriz de correlação de Pearson
corMat <- cor(phen, use = "pairwise.complete.obs")

# Visualizar a matriz de correlação arredondada
round(corMat, 2)
```

### Correlograma

```{r}
# Calcular a matriz de correlação
corr_mat <- cor(phen, method = "pearson")

# Salvar a matriz de correlação em um arquivo
write.table(corr_mat, "Correlacao.txt")

# Realizar o teste de significância para as correlações
res1 <- cor.mtest(phen, conf.level = 0.95)

# Plotar o correlograma
corrplot(
  corr_mat,
  p.mat = res1$p,
  sig.level = 0.05,
  type = "upper",
  method = "color",
  outline = TRUE,
  addgrid.col = "darkgray",
  addrect = 4,
  rect.col = "black",
  rect.lwd = 5,
  cl.pos = "b",
  tl.col = "indianred4",
  tl.cex = 1.1,
  cl.cex = 1,
  addCoef.col = "black",
  number.digits = 2,
  number.cex = 0.8,
  col = colorRampPalette(c("darkred", "white", "darkgreen"))(100)
)
```

### DAPC	

```{r}
# Encontrar os clusters usando DAPC
grp <- find.clusters(phen, max.n = 50, n.pca = 200, scale = TRUE, choose = FALSE)

# Salvar os clusters em um arquivo
write.table(grp$grp, 'Clusters.txt', sep = " ")
```


#### Descrever os clusters usando DAPC

```{r}
# Descrever os clusters usando DAPC
dapc1 <- dapc(phen, grp$grp)

# Plotar o gráfico de dispersão DAPC
scatter(dapc1, posi.da = "bottomleft", bg = "white", pch = 17:22)
```

#### Plotar gráficos de dispersão PCA


```{r}
PCA1x2 <- scatter(dapc1, 1, 2, label.inds = list(air = 0.5, pch = NA), posi.da = "topright")
PCA1x3 <- scatter(dapc1, 1, 3, label.inds = list(air = 0.5, pch = NA), posi.da = "bottomright")
```

#### Interpretação das associações de grupos


```{r}
# Obter as probabilidades a posteriori
probpost <- dapc1$posterior

# Salvar as probabilidades a posteriori em um arquivo
write.table(probpost, 'Prob_a_posteriori.txt', sep = " ")
```

#### Plotar os gráficos de atribuição de grupos


```{r}
# Plotar os gráficos de atribuição de grupos
assignplot(dapc1, subset = 1:60)

# Salvar os grupos a priori em um arquivo
cluster1 <- grp$grp
write.table(cluster1, 'Cluster_a_priori.txt', sep = " ")
```

### Circular heatmap

```{r}
# Definir as cores para a heatmap
col_fun1 = colorRamp2(
  c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
  c(
    "blue4",
    "lightblue",
    "lightgreen",
    "green",
    "darkgreen",
    "lightyellow",
    "yellow",
    "orange",
    "orangered",
    "red",
    "red4"
  )
)

# Calcular o número de clusters
split = cluster1

# Função para padronizar as colunas
padronizar <- function(x) {
  min_val <- min(x)
  max_val <- max(x)
  (x - min_val) / (max_val - min_val) * 100
}

# Aplicar a função de padronização em todas as colunas do dataframe
phen_padronizado <- as.data.frame(lapply(phen, padronizar))

# Resultado
phen_padronizado

# Plotar a circular heatmap
circos.clear()

circos.heatmap(
  phen_padronizado,
  split = split,
  col = col_fun1,
  dend.side = "inside",
  show.sector.labels = TRUE,
  rownames.cex = 0.4,
  dend.callback = function(dend, m, si) {
    color_branches(dend, k = 1, col = split[si])
  }
)


# Adicionar legenda
lgd = Legend(title = "Range", col_fun = col_fun1)
grid.draw(lgd)

# Adicionar rótulos às colunas
circos.track(
  track.index = get.current.track.index(),
  panel.fun = function(x, y) {
    if (CELL_META$sector.numeric.index == 5) {
      cn = 1:7
      n = length(cn)
      circos.text(
        rep(CELL_META$cell.xlim[2], n) + convert_x(1, "mm"),
        1:n - 0.5,
        cn,
        cex = 0.5,
        adj = c(0, 0.5),
        facing = "inside"
      )
    }
  },
  bg.border = NA
)
circos.clear()
```